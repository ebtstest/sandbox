import numpy as np
import pandas as pd
from pandas import DataFrame, Series
import matplotlib.pyplot as plt

s = Series([1, 2, 3, 4])
s
            Out [2]:
            0 1
            1 2
            2 3
            3 4

s[[1, 3]]         # return a Series with the rows with index 1 and 3
            Out [3]:
            1 2
            3 4

dates = pd.date_range('2014-07-01', '2014-07-06')

temps1 = Series([80, 82, 85, 90, 83, 87], index = dates)

temps1.mean()

emps2 = Series([70, 75, 69, 83, 79, 77],  index = dates)
# the following aligns the two by their index values
# and calculates the difference at those matching labels
temp_diffs = temps1 - temps2

temps_df = DataFrame({'Missoula': temps1, 'Philadelphia': temps2})
temps_df

                        Missoula Philadelphia
                2014-07-01    80 70
                2014-07-02    82 75
                2014-07-03    85 69
                2014-07-04    90 83
                2014-07-05    83 79
                2014-07-06    87 77

# return both columns in a different order                
temps_df[['Philadelphia', 'Missoula']]

# retrieve the Missoula column through property syntax
temps_df.Missoula

# add a column to temp_df that contains the difference in temps
temps_df['Difference'] = temp_diffs
temps_df
                            Missoula Philadelphia Difference
                2014-07-01       80 70 10
                2014-07-02       82 75 7
                2014-07-03       85 69 16
                2014-07-04       90 83 7
                2014-07-05       83 79 4
                2014-07-06       87 77 10

# get the columns, which is also an Index object
temps_df.columns
    Index([u'Missoula', u'Philadelphia', u'Difference'], dtype='object')
    
# get the row at array position 1
temps_df.iloc[1]
                Missoula 82
                Philadelphia 75
                Difference  7

# the names of the columns have become the index they have been 'pivoted'
temps_df.ix[1].index
      Index([u'Missoula', u'Philadelphia', u'Difference'], dtype='object')

# retrieve row by index label using .loc
temps_df.loc['2014-07-03']
                Missoula 85
                Philadelphia 69
                Difference 16


# read the data and tell pandas the date column should be
# a date in the resulting DataFrame
df = pd.read_csv('data/test1.csv', parse_dates=['date'])


# read in again, now specify the data column as being the
# index of the resulting DataFrame
df = pd.read_csv('data/test1.csv', parse_dates=['date'], index_col='date')

# imports for reading data from http://finance.yahoo.com
from pandas.io.data import DataReader
from datetime import date
from dateutil.relativedelta import relativedelta
# read the last three months of data for GOOG
goog = DataReader("GOOG", "yahoo", date.today() + relativedelta(months=-3))


#Get Stock price quote from Pandas.io.data
#
import pandas.io.data as web
start = datetime.datetime(2010,1,1)
end = datetime.datetime(2016,5,1)
df = web.DataReader("TSLA", "yahoo", start, end)


# plot the Adj Close values we just read in
goog.plot(y='Adj Close');


# lets do this with a numpy array
import numpy as np
array_to_square = np.arange(0, 100000)
array_to_square ** 2

a1 = np.array([1, 2, 3, 4, 5])
np.size(a1)

# shorthand to repeat a sequence 10 times
a3 = np.array([0]*10)
      array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])


# create a numpy array of 10 0.0's
np.zeros(10)
      array([ 0.,0.,0.,0.,0.,0.,0.,0.,0.,0.])
      
      
# force it to be of int instead of float64
np.zeros(10, dtype=int)
      array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
      
      
# make "a range" starting at 0 and with 10 values
np.arange(0, 10)
      array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
      

# 0 <= x < 10 increment by two
np.arange(0, 10, 2)
      array([0, 2, 4, 6, 8])


# 10 >= x > 0, counting down
np.arange(10, 0, -1)
      array([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])
      
# multiply numpy array by 2
a1 = np.arange(0, 10)
a1 * 2
      array([ 0, 2, 4, 6, 8, 10, 12, 14, 16, 18])

# add two numpy arrays
a2 = np.arange(10, 20)
a1 + a2
      array([10, 12, 14, 16, 18, 20, 22, 24, 26, 28])
      
# create a 2-dimensional array (2x2)
np.array([[1,2], [3,4]])
      array([[1, 2],
             [3, 4]])
             
# create a 1x20 array, and reshape to a 5x4 2d-array
m = np.arange(0, 20).reshape(5, 4)
      array([[ 0, 1, 2, 3],
            [ 4, 5, 6, 7],
            [ 8, 9, 10, 11],
            [12, 13, 14, 15],
            [16, 17, 18, 19]])
            
# can ask the size along a given axis (0 is rows)
np.size(m, 0)

# and 1 is the columns
np.size(m, 1)

#
#   m[row,column]
#   m[row_start:row_end:row_step , column_start:column_end:column_step]

# select an element in 2d array at row 1 column 2
m[1, 2]

# all items in row 1
m[1,]

# all items in column 2
m[:,2]

It is also possible to select specific rows or columns by passing a Python list as an
element of the slice. The following code explicitly selects by position the first, third,
and fourth rows:
        # using a python array, we can select
        # non-contiguous rows or columns
        m[[1,3,4],:]
        array([[ 4, 5, 6, 7],
               [12, 13, 14, 15],
               [16, 17, 18, 19]])

#################################################################################################
Reshaping arrays
#################################################################################################
# create a 9 element array (1x9)
a = np.arange(0, 9)
# and reshape to a 3x3 2-d array
m = a.reshape(3, 3)

# .ravel will generate array representing a flattened 2-d array
raveled = m.ravel()
                  array([[0, 1, 2],
                         [3, 4, 5],
                         [6, 7, 8]])
                  become
                  array([0, 1, 2, 3, 4, 5, 6, 7, 8])
Even though .reshape() and .ravel() do not change the shape of the original
array or matrix, they do actually return a one-dimensional view into the specified
array or matrix. If you change an element in this view, the value in the original array
or matrix is changed.

The .shape property returns a tuple representing the shape of the array:
# we can reshape by assigning a tuple to the .shape property
# we start with this, which has one dimension
flattened.shape
      (9,)

The property can also be assigned a tuple, which will force the array to reshape itself
as specified:
# and make it 3x3
flattened.shape = (3, 3)
# it is no longer flattened
flattened
          array([[ 0, 1, 2],
                 [ 3, 4, 5],
                 [ 6, 7, 8]])

# transpose a matrix
flattened.transpose()
          array([[ 0, 3, 6],
                 [ 1, 4, 7],
                 [ 2, 5, 8]])

The .resize() method functions similarly to the .reshape() method, except
that while reshaping returns a new array with data copied into it, .resize()
performs an in-place reshaping of the array.


# create a function that is applied to all array elements
a = np.arange(5)
def exp (x):
  return x<3 or x>3

# np.vectorize applies the method to all items in an array
np.vectorize(exp)(a)
      array([ True, True, True, False, True], dtype=bool)
      

# boolean select items < 3
r = a<3
# applying the result of the expression to the [] operator
# selects just the array elements where there is a matching True
a[r]
      array([0, 1, 2])
      

# np.sum treats True as 1 and False as 0
# so this is how many items are less than 3
np.sum(a < 3)
      3
      

# This can be applied across two arrays
a1 = np.arange(0, 5)
a2 = np.arange(5, 0, -1)
a1 < a2
      array([ True, True, True, False, False], dtype=bool)
      
      
# and even multi dimensional arrays
a1 = np.arange(9).reshape(3, 3)
a2 = np.arange(9, 0 , -1).reshape(3, 3)
a1 < a2
      array([[ True, True,True],
            [ True, True, False],
            [False, False, False]], dtype=bool)
            


Horizontal stacking combines two arrays in a manner where the columns of the
second array are placed to the right of those in the first array. The function actually
stacks the two items provided in a two-element tuple. The result is a new array with
data copied from the two that are specified:
# horizontally stack the two arrays
# b becomes columns of a to the right of a's columns
np.hstack((a, b))
        array([[ 0, 1, 2, 10, 20, 30],
               [ 3, 4, 5, 40, 50, 60],
               [ 6, 7, 8, 70, 80, 90]])
               
This functionally is equivalent to using the np.concatenate() function while
specifying axis = 1 :
# identical to concatenate along axis = 1
np.concatenate((a, b), axis = 1)
        array([[ 0, 1, 2, 10, 20, 30],
               [ 3, 4, 5, 40, 50, 60],
               [ 6, 7, 8, 70, 80, 90]])
               
Vertical stacking returns a new array with the contents of the second array as
appended rows of the first array:
In [63]:
# vertical stack, adding b as rows after a's rows
np.vstack((a, b))
          array([[ 0, 1, 2],
                [ 3, 4, 5],
                [ 6, 7, 8],
                [10, 20, 30],
                [40, 50, 60],
                [70, 80, 90]])
                
Like np.hstack() , this is equivalent to using the concatenate function, except
specifying axis=0 :
# concatenate along axis=0 is the same as vstack
np.concatenate((a, b), axis = 0)
        
Depth stacking takes a list of arrays and arranges them in order along an additional
axis referred to as the depth:
In [65]:
# dstack stacks each independent column of a and b
np.dstack((a, b))
          rray([[[ 0, 10],
                [ 1, 20],
                [ 2, 30]],
                [[ 3, 40],
                [ 4, 50],
                [ 5, 60]],
                [[ 6, 70],
                [ 7, 80],
                [ 8, 90]]])        

Column stacking performs a horizontal stack of two one-dimensional arrays, making
each array a column in the resulting array:
one_d_a
      array([0, 1, 2, 3, 4])
one_d_b
      array([10, 20, 30, 40, 50])
# stack the two columns
np.column_stack((one_d_a, one_d_b))
            array([[ 0, 10],
                  [ 1, 20],
                  [ 2, 30],
                  [ 3, 40],
                  [ 4, 50]])

Row stacking returns a new array where each one-dimensional array forms one of
the rows of the new array:
# stack along rows
np.row_stack((one_d_a, one_d_b))
            array([[ 0, 1, 2, 3, 4],
                  [10, 20, 30, 40, 50]])


a
      array([[ 0, 1, 2, 3],
            [ 4, 5, 6, 7],
            [ 8, 9, 10, 11]])
We can split this into four arrays, each representing the values in a specific column:
# horiz split the 2-d array into 4 array columns
np.hsplit(a, 2)
      [array([[0, 1],
              [4, 5],
              [8, 9]]), 
       array([[ 2, 3],
              [ 6, 7],
              [10, 11]])]

The np.split() function performs an identical task when using axis=1 :

Vertical splitting works similarly to horizontal splitting, except against the vertical axis,
np.vsplit(a, 2)
        [array([[0, 1, 2],
               [3, 4, 5]]), 
         array([[ 6, 7, 8],
               [ 9, 10, 11]])]

Depth splitting splits three-dimensional arrays. To demonstrate this, we will use the
following three-dimensional array

The .min() and .max() methods return the minimum and maximum values in an
array. The .argmax() and .argmin() functions return the position of the maximum
or minimum value in the array:
# demonstrate some of the properties of NumPy arrays
m = np.arange(10, 19).reshape(3, 3)
      print ("{0} min of the entire matrix".format(m.min()))
      print ("{0} max of entire matrix".format(m.max()))
      print ("{0} position of the min value".format(m.argmin()))
      print ("{0} position of the max value".format(m.argmax()))
      print ("{0} mins down each column".format(m.min(axis = 0)))
      print ("{0} mins across each row".format(m.min(axis = 1)))
      print ("{0} maxs down each column".format(m.max(axis = 0)))

The .mean() , .std() , and .var() methods compute the mathematical mean,
standard deviation, and variance of the values in an array

The sum and products of all the elements in an array can be computed with the
.sum() and .prod() methods:

The cumulative sum and products can be computed with the .cumsum() and
.cumprod() methods:

The .all() method returns True if all elements of an array are true, and .any()
returns True if any element of the array is true.

The .size property returns the number of elements in the array across all dimensions

Also, .ndim returns the overall dimensionality of an array

###################################################################################
pandas series
###################################################################################
# generate a Series from 5 normal random numbers
np.random.seed(123456)
pd.Series(np.random.randn(5))

# create Series from dict
s6 = pd.Series({'a': 1, 'b': 2, 'c': 3, 'd': 4})
            a 1
            b 2
            c 3
            d 4
# length of the Series
len(s)

# .size is also the # of items in the Series
s.size

The .shape property returns a tuple where the first item is the number of items:
# .shape is a tuple with one value
s.shape

The number of the values that are not part of the NaN can be found by using the .count() method:
# count() returns the number of non-NaN values
s.count()

To determine all of the unique values in a Series , pandas provides the .unique() method:
# all unique values
s.unique()

Also, the count of each of the unique items in a Series can be obtained using
.value_counts() :
# count of non-NaN values, returned max to min order
s.value_counts()
          1 2
          7 1
          6 1
          5 1
          4 1
          3 1
          2 1
          0 1
          

###########################################################################################
Looking up values in Series
###########################################################################################
# single item lookup by index ('a' is the index)
s3['a']

# lookup by position since the index is not an integer
s3[1]

# multiple items
s3[['a', 'c']]

# mean of numpy array values with a NaN
nda = np.array([1, 2, 3, 4, np.NaN])
nda.mean()
        nan
        
When encountering a NaN value, NumPy simply returns NaN . pandas changes this,
so that NaN values are ignored:
# ignores NaN values
s = pd.Series(nda)
s.mean()
      2.5
      
reindex a series:
# change the index
s.index = ['a', 'b', 'c', 'd', 'e']

he following creates a new index for the concatenated result which has
sequential and distinct values.
# reset the index
combined.index = np.arange(0, len(combined))

np.random.seed(123456)
s1 = pd.Series(np.random.randn(4), ['a', 'b', 'c', 'd'])
# reindex with different number of labels
# results in dropped rows and/or NaN's
s2 = s1.reindex(['a', 'c', 'g'])

# fill with 0 instead of NaN
s2 = s.copy()
s2.reindex(['a', 'f'], fill_value=0)
            a -0.173215
            f 0.000000
            
s3 = pd.Series(['red', 'green', 'blue'], index=[0, 3, 5])
s3
        0 red
        3 green
        5 blue
# forward fill example
s3.reindex(np.arange(0,7), method='ffill')
        0 red
        1 red
        2 red
        3 green
        4 green
        5 blue
        6 blue
The following example fills backward using method='bfill' :
# backwards fill example
s3.reindex(np.arange(0,7), method='bfill')
        0 red
        1 green
        2 green
        3 green
        4 blue
        5 blue
        6 NaN


# remove a row / item
del(s['a'])


# equivalent to s.tail(4).head(3)
s[-4:-1]


##############################################################################
The pandas DataFrame Object
##############################################################################
# create a DataFrame from a 2-d ndarray
pd.DataFrame(np.array([[10, 11], [20, 21]]))

# what's the shape of this DataFrame
df1.shape
# it is two rows by 5 columns
          (2,5)

# specify column names
df = pd.DataFrame(np.array([[10, 11], [20, 21]]), columns=['a', 'b'])

# retrieve just the names of the columns by position
"{0}, {1}".format(df.columns[0], df.columns[1])

# rename the columns
df.columns = ['c1', 'c2']

# create a DataFrame with named columns and rows
df = pd.DataFrame(np.array([[0, 1], [2, 3]]),
                  columns=['c1', 'c2'],
                  index=['r1', 'r2'])
                  
# retrieve the index of the DataFrame
df.index

# create a DataFrame with two Series objects
# and a dictionary
s1 = pd.Series(np.arange(1, 6, 1))
s2 = pd.Series(np.arange(6, 11, 1))
pd.DataFrame({'c1': s1, 'c2': s2})
              c1 c2
            0 1 6
            1 2 7
            2 3 8
            3 4 9
            4 5 10
            
# demonstrate alignment during creation
s3 = pd.Series(np.arange(12, 14), index=[1, 2])
df = pd.DataFrame({'c1': s1, 'c2': s2, 'c3': s3})
df
                         c1 c2 c3
                        0 1 6 NaN
                        1 2 7 12
                        2 3 8 13
                        3 4 9 NaN
                        4 5 10 NaN

# read in the data and print the first five rows
# use the Symbol column as the index, and
# only read in columns in positions 0, 2, 3, 7
sp500 = pd.read_csv("data/sp500.csv",
                        index_col='Symbol',
                        usecols=[0, 2, 3, 7])

# get first and second columns (1 and 2) by location
sp500[[1, 2]].head()

# it's a DataFrame, not a Series
type(sp500[[1]].head())
            pandas.core.frame.DataFrame
            
